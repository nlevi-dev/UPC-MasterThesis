{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-23 11:31:04.164005: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-10-23 11:31:04.180169: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-10-23 11:31:04.185118: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    }
   ],
   "source": [
    "import os, warnings\n",
    "warnings.simplefilter(action='ignore',category=FutureWarning)\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL']='2'\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "import sys\n",
    "sys.path.insert(1,'source')\n",
    "from DataGenerator import DataGenerator\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "datagen_props = {\n",
    "    'path'          : 'source/data',     #path of the data\n",
    "    'seed'          : 42,         #seed for the split\n",
    "    'split'         : 0.8,        #train/all ratio\n",
    "    'train'         : True,       #training/testing split\n",
    "    'control'       : True,       #include control data points\n",
    "    'huntington'    : False,      #include huntington data points\n",
    "    'batch_size'    : 50000,      #batch size\n",
    "    'spatial'       : False,      #keep spaital format of flatten voxels in the brain region\n",
    "    'left'          : True,       #include left hemisphere data (if both false, concatenate the left and right hemisphere layers)\n",
    "    'right'         : True,       #include right hemisphere data\n",
    "    'threshold'     : 0.5,        #if float value provided, it thresholds the connectivty map\n",
    "    'binarize'      : False,      #only works if threshold if greater or equal than half, and then it binarizes the connectivity map\n",
    "    'not_connected' : False,      #only works if thresholded and not single, and then it appends an extra encoding for the 'not connected'\n",
    "    'single'        : 0,          #if int index value is provided, it only returns a specified connectivity map\n",
    "    'target'        : False,\n",
    "    'roi'           : False,\n",
    "    'brain'         : False,\n",
    "    'features'      : [],         #used radiomics features (emptylist means all)\n",
    "    'features_vox'  : [],         #used voxel based radiomics features (emptylist means all)\n",
    "    'radiomics'     : ['b25'],    #used radiomics features bin settings\n",
    "    'radiomics_vox' : ['k5_b25'], #used voxel based radiomics features kernel and bin settings\n",
    "}\n",
    "\n",
    "datagen = DataGenerator(**datagen_props)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 106)\n",
      "(50000, 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 92)\n",
      "(50000, 14)\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28mprint\u001b[39m(datagen\u001b[38;5;241m.\u001b[39mx_shape)\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(datagen\u001b[38;5;241m.\u001b[39my_shape)\n\u001b[0;32m----> 3\u001b[0m x, y \u001b[38;5;241m=\u001b[39m \u001b[43mdatagen\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__getitem__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(x\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(y\u001b[38;5;241m.\u001b[39mshape)\n",
      "File \u001b[0;32m/ZFS/public/subjects/UPC/documents/semester 3/MT/MasterThesis/source/DataGenerator.py:148\u001b[0m, in \u001b[0;36mDataGenerator.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[38;5;28mprint\u001b[39m(x\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m    147\u001b[0m \u001b[38;5;28mprint\u001b[39m(y\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m--> 148\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx_shape \u001b[38;5;241m==\u001b[39m x\u001b[38;5;241m.\u001b[39mshape\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39my_shape \u001b[38;5;241m==\u001b[39m y\u001b[38;5;241m.\u001b[39mshape\n\u001b[1;32m    150\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m [x, y]\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print(datagen.x_shape)\n",
    "print(datagen.y_shape)\n",
    "x, y = datagen.__getitem__(5)\n",
    "print(x.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "# model = Sequential(name='FFN')\n",
    "# model.add(Dense(128,activation='silu', input_shape=(len(features_train[0]),)))\n",
    "# model.add(Dense(128,activation='silu'))\n",
    "# model.add(Dense(1,activation='silu'))\n",
    "# model.summary()\n",
    "\n",
    "# model.compile(loss='mean_absolute_error', optimizer='adam')\n",
    "# history = model.fit(features_train,gs_train,\n",
    "#     epochs=200,\n",
    "#     batch_size=128,\n",
    "#     verbose=0,\n",
    "# )\n",
    "\n",
    "# predict_train = np.squeeze(model.predict(features_train, verbose=0))\n",
    "# predict_test = np.squeeze(model.predict(features_test, verbose=0))\n",
    "# correlation_train = pearsonr(predict_train, gs_train)[0]\n",
    "# print(\"Pearson correlation for training:\", correlation_train)\n",
    "# correlation_test = pearsonr(predict_test, gs_test)[0]\n",
    "# print(\"Pearson correlation for test:\", correlation_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda 3.9 tf 2.17",
   "language": "python",
   "metadata": {
    "debugger": true
   },
   "name": "tensorflow2.17python3.9",
   "resource_dir": "/projects/d0a370e9-39db-4874-9788-96e60b5b476d/.local/share/jupyter/kernels/tensorflow2.17python3.9"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}