\label{sec:conclusions}

This foundational project has huge potential thanks to the possible returns and applications of the approach proposed. Due to deployment time and resource limitations, the experiments only focused on the Basal Ganglia, so by no means any of the performance metrics prove that a generalized solution is viable. However the \ac{FA} and \ac{MD} predictions are really promising, and would be interesting to see how would it perform on the entire brain, and not just the \ac{ROI}. On the other hand, the Relative Connectivity predictions are not even nearly precise enough to call them usable, but, admittedly, the labels themselves will inherently contain quite a bit of noise, due to the very sensitive process of extracting the labels with tractography.\par
This project only delved into a tiny fraction of the endless sea of possible preprocessing approaches, and it only experimented with some very basic model architectures. Nevertheless, the viability of this approach and hypothesis is not disproven, but it definitely needs the implementation of some new ideas to make it fully functional.\par

Key conclusions regarding different imaging modalities and spatial normalization primarily stem from the \ac{FA} and Relative Connectivity experiments. The \ac{MD} and Subcortical Segmentation experiments showed only marginal differences across modalities, making it difficult to draw definitive conclusions from these results.\par
In general, experiments conducted in normalized space slightly outperformed those in native space (by 1-2\%). This could be attributed to the removal of some variance in normalized space or reduced misalignment between anatomical \ac{MRI} and \ac{DTI} images.\par
An interesting observation across many experiments was that the T1/T2 modality, despite showing marginally better training performance (by 1-2\%), exhibited more significant overfitting. This resulted in similar validation performance and slightly worse test performance (by 1-2\%) compared to T1. Notably, T1/T2 performed comparably or better with less input data, such as when only a single kernel size of voxel-based features were provided. This suggests that the T1/T2 modality, although not performing as well overall as T1, might harbor untapped potential, particularly in certain conditions.\par
There are alternative explanations for why the results do not fully align with state-of-the-art studies that use the T1/T2 ratio as a myelin proxy. One possible factor is the non-isotropic voxel size of our T2 images, which, when combined with 3D radiomic feature extraction, may introduce noise or bias, particularly affecting the \ac{GLRLM} feature class. This issue could distort feature values due to the skewed run lengths along the affected axis.\par
The neurodegeneration observed in patients with \ac{HD} significantly impacts model performance, likely due to the higher variance in their data. This issue could potentially be mitigated by increasing the dataset size to account for this variability. However, mixing Control and Patient records resulted in only a slight performance decrease, suggesting that combining the two groups lead to more robust models.\par
The inclusion of clinical features exhibited inconsistent results across experiments and modalities. While some configurations led to improved performance in Patient records, these models never outperformed those trained on Control or Control+Patient data, indicating that clinical features may not be a beneficial input in this context.\par
Data augmentation had minimal impact on the native space experiments, likely due to the limited variation introduced by the mild rotations applied during augmentation. More aggressive augmentation could compromise applicability, as it would likely introduce unrealistic variations not typically observed in the raw \ac{MRI} scans.\par
It was also consistently shown in the experiments, that the logarithmic data normalization on the heavily skewed features, did improve performance.\par
Exploring hemisphere-specific datapoints revealed an unexpected finding: the right hemisphere consistently performed better than the left. This pattern can be explained in part by the asymmetrical neurodegeneration in \ac{HD}, where the left hemisphere is affected more severely. Interestingly, this trend was also present in the Control group, which warrants further investigation. Ultimately, combining both hemispheres resulted in models that generalized well, even for the left hemisphere, indicating that training on a mix of hemispheric data may lead to more versatile models.\par

\section{Future Improvements}
\label{sec:improve}

As mentioned in \reflink{sec:seqback}{subsection}, there was a serious oversight during the execution of the exhaustive sequential backwards feature selection. At the time it was believed that the model was performing better on balanced data, due to a bug in the code. Thus, all of these models are performing much worse than the models during the experimentation. The bug was fixed, but due to limited time and resources the feature selection was not executed again.\par
Further investigation of the sex imbalance issue reported in subsection \reflink{sec:inclusive}{subsection} reveals that, with the seed used for the experiments results are not terribly imbalanced for the most part, but there is definitely room for improvement by enforcing a constant ratio. The male/(male+female) ratio for the control record splits is $0.49$/$0.67$/$0.67$ (train/validation/test), while it is $0.62$/$0.5$/$1$ for the patient records.\par
Additionally, one aspect was not investigated thoroughly over the thesis: the kernel size, binning parameters, and feature class relationships during the voxel based feature extraction. For the sake of simplicity, only a unified binning method was used for all kernel sizes and all feature classes. But, logically, the binning parameters could be optimized for each kernel size and feature class. For example, the \ac{GLRLM} feature class could yield fundamentally different features even just by adjusting the bin size a tiny bit at large kernel sizes.\par
The selection of the most efficient kernel size combinations was not investigated thoroughly either. Due to limited resources, the maximum kernel size used was 21, but there was no reason to stop there.\par
Ultimately, and even with the relatively few simple aspects that were taken into consideration during this thesis, the hyperparameter space is gigantic and some compromises had to be made. After investing over 500 hours into this project, the educated guesses for these potential improvements are:
\begin{itemize}
  \item The feature selection should have a marginal improvement on the model performance.
  \item The gender imbalance should not have a measurable impact on the model performance on this scale (with less than 70 available records in total).
  \item The binning parameter optimization for the kernel sizes and feature classes would probably have a big impact on the model performance.
\end{itemize}
And lastly, all experiments should be repeated at least a few times, with different splits and seeds. And the experiments should be evaluated with the means and medians of the model performance indicators, across different runs.\par
Ultimately there are two paths that could be followed in order to pursue this approach further: First, the \ac{FA} and \ac{MD} experiments could be expanded to the entire brain and a generalized model could be developed. The second one would entail the refinement of the Relative Connectivity experiments, as they require overall improvements and the development of new ideas.







