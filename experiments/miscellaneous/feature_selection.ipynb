{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-12-03T22:02:03.366117Z",
     "iopub.status.busy": "2024-12-03T22:02:03.365620Z",
     "iopub.status.idle": "2024-12-03T22:02:03.950169Z",
     "shell.execute_reply": "2024-12-03T22:02:03.949244Z"
    }
   },
   "outputs": [
   ],
   "source": [
    "import os\n",
    "while 'source' not in os.listdir():\n",
    "    os.chdir('..')\n",
    "os.chdir('source')\n",
    "FORCE = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-12-03T22:02:03.954848Z",
     "iopub.status.busy": "2024-12-03T22:02:03.954307Z",
     "iopub.status.idle": "2024-12-03T22:02:05.549304Z",
     "shell.execute_reply": "2024-12-03T22:02:05.548577Z"
    }
   },
   "outputs": [
   ],
   "source": [
    "props={\n",
    "    'path'          : 'data',\n",
    "    'seed'          : 42,\n",
    "    'split'         : 0.8,\n",
    "    'test_split'    : 0.5,\n",
    "    'control'       : True,\n",
    "    'huntington'    : False,\n",
    "    'left'          : False,\n",
    "    'right'         : False,\n",
    "    'threshold'     : 0.6,\n",
    "    'binarize'      : True,\n",
    "    'not_connected' : True,\n",
    "    'single'        : None,\n",
    "    'features'      : [],\n",
    "    'features_vox'  : [],\n",
    "    #'radiomics'     : ['b10','b25','b50','b75'],\n",
    "    #'radiomics_vox' : ['k5_b25','k7_b25','k9_b25','k11_b25'],\n",
    "    'radiomics'     : [\n",
    "        #{'sp':'native','im':'t1','fe':['b25'],'fi':['roi','t1_mask']},\n",
    "    ],\n",
    "    'space'         : 'native',\n",
    "    'radiomics_vox' : [\n",
    "        {'im':'t1','fe':['k5_b25','k7_b25','k9_b25','k11_b25','k13_b25','k15_b25','k17_b25','k19_b25','k21_b25']},\n",
    "    ],\n",
    "    'rad_vox_norm'  : 'norm',\n",
    "    'outp'          : 'connectivity',\n",
    "    'balance_data'  : True,\n",
    "    'targets_all'   : False,\n",
    "    'collapse_max'  : False,\n",
    "    'debug'         : False,\n",
    "}\n",
    "architecture={\n",
    "    'activation'    : 'sigmoid',\n",
    "    'layers'        : [2048,1024,512,256,128],\n",
    "    'loss'          : 'CCE',\n",
    "    'learning_rate' : 0.001,\n",
    "    'batch_size'    : 100000,\n",
    "    'patience'      : 7,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import mixed_precision\n",
    "#H100\n",
    "mixed_precision.set_global_policy('mixed_float16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "from util import getHashId, pickleSave, pickleLoad, getAccuarcy, predictInBatches\n",
    "from ModelClassificationFNN import *\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "path = props['path']+'/models'\n",
    "\n",
    "def runModel(props):\n",
    "    #get data\n",
    "    gen = DataGenerator(**props)\n",
    "    train, val, test = gen.getData()\n",
    "    #get model id and hash\n",
    "    HASHID, HASH = getHashId(architecture,props)\n",
    "    #compile model\n",
    "    stop = tf.keras.callbacks.EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=architecture['patience'],\n",
    "    )\n",
    "    save = tf.keras.callbacks.ModelCheckpoint(\n",
    "        filepath=path+'/{}.weights.h5'.format(HASHID),\n",
    "        monitor='val_loss',\n",
    "        mode='min',\n",
    "        save_best_only=True,\n",
    "        save_weights_only=True,\n",
    "    )\n",
    "    model = buildModel(train[0].shape[1], train[1].shape[1], activation=architecture['activation'], layers=architecture['layers'])\n",
    "    model.compile(loss=locals()[architecture['loss']], optimizer=Adam(learning_rate=architecture['learning_rate']), jit_compile=True, metrics=[STD,MAE])\n",
    "    #train model\n",
    "    if FORCE or not os.path.exists(path+'/{}.pkl'.format(HASHID)):\n",
    "        history = model.fit(DataWrapper(train,architecture['batch_size']),\n",
    "            validation_data=DataWrapper(val,architecture['batch_size'],False),\n",
    "            epochs=10000,\n",
    "            verbose=0,\n",
    "            callbacks = [save,stop],\n",
    "        )\n",
    "        pickleSave(path+'/{}.pkl'.format(HASHID), history.history)\n",
    "    model.load_weights(path+'/{}.weights.h5'.format(HASHID))\n",
    "    #return accuracy\n",
    "    return getAccuarcy(val[1],predictInBatches(model,val[0],architecture['batch_size']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-12-03T22:02:05.603394Z",
     "iopub.status.busy": "2024-12-03T22:02:05.602740Z",
     "iopub.status.idle": "2024-12-03T22:03:11.810287Z",
     "shell.execute_reply": "2024-12-03T22:03:11.809728Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "(4339345, 783)\n",
      "(4339345, 8)\n",
      "validation\n",
      "(669326, 783)\n",
      "(669326, 8)\n",
      "test\n",
      "(492897, 783)\n",
      "(492897, 8)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from DataGeneratorClassificationFNN import DataGenerator\n",
    "\n",
    "j0 = 0\n",
    "i0 = 0\n",
    "\n",
    "#load all available features\n",
    "features_oc = np.load(props['path']+'/preprocessed/features_vox.npy')\n",
    "features_ex = []\n",
    "#pretty print\n",
    "features_maxlen = max([len(f) for f in features_oc])\n",
    "def printStatus(ite, fea, ac):\n",
    "    ret = str(ite)\n",
    "    while len(ret) < 4:\n",
    "        ret += ' '\n",
    "    ret += fea\n",
    "    while len(ret) < features_maxlen:\n",
    "        ret += ' '\n",
    "    ret += ' '+str(round(ac*100,1))\n",
    "    return ret\n",
    "#keep track of accuracies and excluded features\n",
    "accuracies = []\n",
    "excludeds = []\n",
    "#keep track of best accuracies\n",
    "last_iter_best_idx = 0\n",
    "last_iter_best = 0\n",
    "best_idxs = []\n",
    "#get baseline of all features\n",
    "baseline = runModel(props)\n",
    "accuracies.append(baseline)\n",
    "excludeds.append([])\n",
    "last_iter_best_idx = 0\n",
    "last_iter_best = accuracies[0]\n",
    "best_idxs.append(0)\n",
    "\n",
    "#==== LOAD SAVED ====#\n",
    "if os.path.exists('state.pkl'):\n",
    "    state = pickleLoad('state.pkl')\n",
    "    j0 = state['j']\n",
    "    i0 = state['i']\n",
    "    accuracies = state['accuracies']\n",
    "    excludeds = state['excludeds']\n",
    "    last_iter_best_idx = state['last_iter_best_idx']\n",
    "    last_iter_best = state['last_iter_best']\n",
    "    best_idxs = state['best_idxs']\n",
    "#====================#\n",
    "\n",
    "#top-down exhaustive search\n",
    "max_iter = len(features_oc)\n",
    "for j in range(j0,max_iter):\n",
    "    current_features = [f for f in features_oc if f not in features_ex]\n",
    "    current_best_idx = -1\n",
    "    current_best = 0\n",
    "    for i in range(i0,len(current_features)):\n",
    "        #==== SAVE ====#\n",
    "        state = {\n",
    "            'j':j,\n",
    "            'i':i,\n",
    "            'accuracies':accuracies,\n",
    "            'excludeds':excludeds,\n",
    "            'last_iter_best_idx':last_iter_best_idx,\n",
    "            'last_iter_best':last_iter_best,\n",
    "            'best_idxs':best_idxs,\n",
    "        }\n",
    "        pickleSave('state.pkl',state)\n",
    "        #==============#\n",
    "        currently_excluded = current_features[i]\n",
    "        props['features_vox'] = [f for f in current_features if f != currently_excluded]\n",
    "        ac = runModel(props)\n",
    "        if acs[BESTIDX] > current_best:\n",
    "            current_best = ac\n",
    "            current_best_idx = len(accuracies)\n",
    "        accuracies.append(ac)\n",
    "        excludeds.append(features_ex+[currently_excluded])\n",
    "        printStatus(i,currently_excluded,ac)\n",
    "    if current_best < last_iter_best:\n",
    "        print('Validation accuracy not increasing, stopping!')\n",
    "        break\n",
    "    print('===================================')\n",
    "    last_iter_best_idx = current_best_idx\n",
    "    last_iter_best = current_best\n",
    "    best_idxs.append(current_best_idx)\n",
    "    features_ex = excludeds[current_best_idx]\n",
    "    print(features_ex)\n",
    "    printStatus(j,features_ex[-1],accuracies[current_best_idx])\n",
    "    print('===================================')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf14",
   "language": "python",
   "metadata": {
    "debugger": true
   },
   "name": "tf14",
   "resource_dir": "/projects/d0a370e9-39db-4874-9788-96e60b5b476d/.local/share/jupyter/kernels/tf14"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}