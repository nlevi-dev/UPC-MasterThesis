{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU says hello!\n",
      "-name: 12th Gen Intel(R) Core(TM) i5-12600KF\n",
      "-architecture: X86_64\n",
      "-bits: 64\n",
      "-frequency: 801.5760 MHz\n",
      "-threads: 16\n",
      "-l3_cache: 20480 KB\n",
      "-l2_cache: 6.3 MiB\n",
      "-l1_cache: 240 KiB\n",
      "RAM says hello!\n",
      "-virtual: 125.61 GB\n",
      "-swap: 256.0 GB\n",
      "Python says hello!\n",
      "-python: 3.9.19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-25 11:51:26.306690: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-09-25 11:51:26.386732: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-09-25 11:51:26.410607: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-tensorflow: 2.17.0\n",
      "-keras: 3.5.0\n",
      "GPUs saying hello!\n",
      "-name: NVIDIA GeForce RTX 3060\n",
      "-vram: 10.79 GB\n",
      "-name: Tesla P40\n",
      "-vram: 23.34 GB\n",
      "Drivers saying hello!\n",
      "-nvidia: 560.35.03\n",
      "-cuda: 12.6\n",
      "===============================\n",
      "Mixed precision enabled!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1727265088.323468   45685 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1727265088.324515   45685 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1727265088.434083   45685 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1727265088.435325   45685 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1727265088.435510   45685 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1727265088.436674   45685 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1727265088.449098   45685 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1727265088.450094   45685 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1727265088.450187   45685 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1727265088.451850   45685 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1727265088.451937   45685 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1727265088.453593   45685 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n"
     ]
    }
   ],
   "source": [
    "# boilerplate sanity check\n",
    "import os,warnings,cpuinfo,multiprocessing,psutil,sys\n",
    "warnings.simplefilter(action='ignore',category=FutureWarning)\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL']='2'\n",
    "try:cpu=cpuinfo.get_cpu_info();print('CPU says hello!\\n-name: {}\\n-architecture: {}\\n-bits: {}\\n-frequency: {}\\n-threads: {}\\n-l3_cache: {}\\n-l2_cache: {}\\n-l1_cache: {}'.format(cpu['brand'],cpu['arch'],cpu['bits'],cpu['hz_actual'],multiprocessing.cpu_count(),cpu['l3_cache_size'],cpu['l2_cache_size'],cpu['l1_data_cache_size']))\n",
    "except:print('Failed to get all CPU info!')\n",
    "try:print('RAM says hello!\\n-virtual: {} GB\\n-swap: {} GB'.format(round(psutil.virtual_memory().total/1024**3,2),round(psutil.swap_memory().total/1024**3,2)))\n",
    "except:print('Failed to get all RAM info!')\n",
    "print('Python says hello!\\n-python: {}'.format(sys.version.split(' ')[0]))\n",
    "try:\n",
    "    import tensorflow as tf;import keras;from tensorflow.python.client import device_lib;from tensorflow.keras import mixed_precision;from tensorflow.python.framework.ops import disable_eager_execution;gpus=[];\n",
    "    print('-tensorflow: {}'.format(tf.version.VERSION))\n",
    "    print('-keras: {}'.format(keras.__version__))\n",
    "    for device in device_lib.list_local_devices():\n",
    "        try:\n",
    "            if device.device_type=='GPU':\n",
    "                name=device.name\n",
    "                try:\n",
    "                    splitted=device.physical_device_desc.split(',')\n",
    "                    for part in splitted:\n",
    "                        if'name:'in part or'Name:'in part:name=part.split(':')[1].strip()\n",
    "                except:pass\n",
    "                gpus.append('\\n-name: {}\\n-vram: {} GB'.format(name,round(device.memory_limit/1000**3,2)))\n",
    "        except:pass\n",
    "    if len(gpus)>0:\n",
    "        print('GPU{} hello!{}'.format('s saying'if len(gpus)>1 else' says',''.join(gpus)))\n",
    "        try:\n",
    "            smi=os.popen('nvidia-smi').read().split('\\n')[2];d=smi.find('Driver Version')+16;c=smi.find('CUDA Version')+14\n",
    "            print('Drivers saying hello!\\n-nvidia: {}\\n-cuda: {}'.format(smi[d:d+10].strip(),smi[c:c+5].strip()))\n",
    "        except:pass\n",
    "    else:print('GPU not found!')\n",
    "except:print('GPU not found! Check tensorflow-gpu and cudatoolkit installations!')\n",
    "print('===============================')\n",
    "# try:\n",
    "#     disable_eager_execution()\n",
    "#     print('Eager execution disabled!')\n",
    "# except:\n",
    "#     print('Failed to disable eager execution!')\n",
    "try:\n",
    "    mixed_precision.set_global_policy('mixed_float16')\n",
    "    print('Mixed precision enabled!')\n",
    "except:\n",
    "    print('Failed to enable mixed precision!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda 3.9 tf 2.17",
   "language": "python",
   "metadata": {
    "debugger": true
   },
   "name": "tensorflow2.17python3.9",
   "resource_dir": "/projects/1ee8887d-cf15-48e1-970b-ed87e4d3623f/.local/share/jupyter/kernels/tensorflow2.17python3.9"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}